import os
import torch
import gradio as gr
from transformers import pipeline
from PIL import Image

# ================= äº‘ç«¯éƒ¨ç½²é€‚é…é…ç½® =================
# 1. æ¨¡å‹ç¼“å­˜è·¯å¾„ï¼ˆé€‚é…äº‘å¹³å°ï¼‰
os.environ['HF_HOME'] = '/tmp/hf_models'
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ['TORCH_HOME'] = '/tmp/torch_cache'

# 2. è®¾å¤‡è‡ªåŠ¨é€‚é…ï¼ˆäº‘å¹³å°å¤šä¸ºCPUï¼Œè‡ªåŠ¨é™çº§ï¼‰
DEVICE = 0 if (torch.cuda.is_available() and torch.cuda.device_count() > 0) else -1
print(f">>> è¿è¡Œè®¾å¤‡: {'GPU (CUDA)' if DEVICE == 0 else 'CPU'}")
print(f">>> æ¨¡å‹ç¼“å­˜è·¯å¾„: {os.environ['HF_HOME']}")

# ======================================================

class ImageGuard:
    def __init__(self):
        print("\n" + "="*40)
        print(">>> æ­£åœ¨å¯åŠ¨ã€äº‘ç«¯ç‰ˆã€‘å›¾ç‰‡é‰´åˆ«æ ¸å¿ƒ...")
        print(">>> æ¨¡å¼ï¼šé«˜çµæ•åº¦ (é’ˆå¯¹ Flux/SDXL ä¼˜åŒ–)")
        print(">>> é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        print("="*40 + "\n")
        
        # --- æ¨¡å‹ A: çº¹ç†ä¸“å®¶ ---
        print(">>> [1/2] åŠ è½½çº¹ç†åˆ†ææ¨¡å‹ (umm-maybe)...")
        try:
            self.pipe_texture = pipeline(
                "image-classification", 
                model="umm-maybe/AI-image-detector", 
                device=DEVICE,
                # äº‘ç«¯ä¼˜åŒ–ï¼šç¦ç”¨ç¼“å­˜å‡å°‘å†…å­˜å ç”¨
                model_kwargs={"low_cpu_mem_usage": True}
            )
        except Exception as e:
            print(f"âŒ çº¹ç†æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.pipe_texture = None

        # --- æ¨¡å‹ B: ç»“æ„ä¸“å®¶ ---
        print(">>> [2/2] åŠ è½½ç»“æ„åˆ†ææ¨¡å‹ (dima806)...")
        try:
            self.pipe_struct = pipeline(
                "image-classification", 
                model="dima806/ai_generated_image_detection", 
                device=DEVICE,
                model_kwargs={"low_cpu_mem_usage": True}
            )
        except Exception as e:
            print(f"âŒ ç»“æ„æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.pipe_struct = None
        
        print(">>> åˆå§‹åŒ–å®Œæˆï¼")

    def _get_score(self, pipe, image):
        if not pipe: return 0.0
        try:
            results = pipe(image)
            ai_keywords = ['fake', 'artificial', 'generated', 'ai', 'computer']
            real_keywords = ['human', 'real', 'photo', 'natural']
            
            for res in results:
                if any(k in res['label'].lower() for k in ai_keywords):
                    return res['score']
            for res in results:
                if any(k in res['label'].lower() for k in real_keywords):
                    return 1.0 - res['score']
            return 0.0
        except Exception as e:
            print(f"âŒ è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")
            return 0.0

    def analyze(self, image):
        if image is None: return "âš ï¸ è¯·ä¸Šä¼ å›¾ç‰‡"
        
        # è·å–åˆ†æ•°
        score_tex = self._get_score(self.pipe_texture, image)
        score_str = self._get_score(self.pipe_struct, image)
        
        # æ ¸å¿ƒç®—æ³•ï¼šé«˜æ•åŠ æƒ
        base_risk = max(score_tex, score_str)
        
        verdict = ""
        desc = ""
        
        # åˆ¤å®šé€»è¾‘ (é˜ˆå€¼ 15%)
        if base_risk > 0.8:
            verdict = "ğŸ”´ [ç¡®è®¤] æå¤§æ¦‚ç‡æ˜¯ AI ç”Ÿæˆ"
            desc = "æ£€æµ‹åˆ°æ˜æ˜¾çš„ç”Ÿæˆå¼æŒ‡çº¹ï¼Œæ¯«æ— ç–‘é—®çš„ AI ä½œå“ã€‚"
        elif base_risk > 0.5:
            verdict = "ğŸŸ  [é«˜ç–‘] åŒ…å«å¤§é‡åˆæˆç‰¹å¾"
            desc = "è™½ç„¶å…‰å½±è‡ªç„¶ï¼Œä½†çº¹ç†ç»†èŠ‚æš´éœ²äº† AI èº«ä»½ã€‚"
        elif base_risk > 0.15: 
            verdict = "ğŸŸ¡ [å­˜ç–‘] ç–‘ä¼¼ Flux/SDXL é«˜ä»¿"
            desc = f"æ£€æµ‹åˆ°å¼‚å¸¸çº¹ç†ä¿¡å· ({base_risk:.1%})ã€‚çœŸå®ç›¸æœºç›´å‡ºç…§ç‰‡å‡ ä¹ä¸ä¼šè¶…è¿‡ 10%ã€‚"
        else:
            verdict = "ğŸŸ¢ [çœŸå®] ç¬¦åˆæ‘„å½±ç‰¹å¾"
            desc = "å™ªç‚¹åˆ†å¸ƒè‡ªç„¶ï¼Œæœªæ£€æµ‹åˆ° AI ç—•è¿¹ã€‚"

        details = f"ğŸ“Š ä¸“å®¶ä¼šè¯Šæ•°æ®:\n"
        details += f"â€¢ çº¹ç†åˆ†æ (ç»†èŠ‚): {score_tex:.1%}\n"
        details += f"â€¢ ç»“æ„åˆ†æ (æ„å›¾): {score_str:.1%}\n"
        details += "-" * 30 + "\n"
        details += "ğŸ’¡ é˜ˆå€¼è¯´æ˜: æœ¬ç³»ç»Ÿ >15% å³è§†ä¸ºå¼‚å¸¸"

        return f"{verdict}\n\n{desc}\n\n{details}"

# --- å¯åŠ¨äº‘ç«¯ç•Œé¢ ---
if __name__ == "__main__":
    guard = ImageGuard()
    
    # äº‘ç«¯é€‚é…ï¼šè‡ªå®šä¹‰CSSä¼˜åŒ–æ˜¾ç¤º
    custom_css = """
    .gradio-container {background-color: #f9f9f9; max-width: 1200px !important; margin: 0 auto;}
    .gr-button {font-size: 16px !important; padding: 12px !important;}
    .gr-textbox {font-size: 14px !important; line-height: 1.6 !important;}
    """

    with gr.Blocks(title="AI å›¾åƒé‰´åˆ«ç»ˆæç‰ˆ", theme=gr.themes.Soft(), css=custom_css) as demo:
        gr.Markdown("# ğŸ¦… AI å›¾åƒé‰´åˆ« (äº‘ç«¯ç»ˆæç‰ˆ)")
        gr.Markdown("ä¸“æ”» Flux / Midjourney v6 / SDXL é«˜å†™å®å›¾ç‰‡æ£€æµ‹ | äº‘ç«¯éƒ¨ç½²ç‰ˆ")
        
        with gr.Row():
            with gr.Column(scale=1):
                image_input = gr.Image(type="pil", label="æ‹–å…¥å›¾ç‰‡è¿›è¡Œæ£€æµ‹", height=400)
                btn = gr.Button("å¼€å§‹æ·±åº¦æ‰«æ", variant="primary", size="lg")
            
            with gr.Column(scale=1):
                result_output = gr.Textbox(label="é‰´å®šæŠ¥å‘Š", lines=12)
        
        # ç»‘å®šç‚¹å‡»äº‹ä»¶
        btn.click(guard.analyze, inputs=image_input, outputs=result_output)

    # äº‘ç«¯å¯åŠ¨é…ç½®ï¼ˆå…³é”®ï¼é€‚é…äº‘å¹³å°ç«¯å£å’Œè®¿é—®ï¼‰
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=int(os.getenv("PORT", 7860)),  # è¯»å–äº‘å¹³å°åˆ†é…çš„ç«¯å£
        share=False,  # å…³é—­ä¸´æ—¶åˆ†äº«é“¾æ¥
        show_error=True,  # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ä¾¿äºè°ƒè¯•
        quiet=False  # è¾“å‡ºå¯åŠ¨æ—¥å¿—
    )
